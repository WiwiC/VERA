{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb9b94b",
   "metadata": {},
   "source": [
    "## Key install commands (Python 3.10):\n",
    "\n",
    "### Core audio + features:\n",
    "\n",
    "pip install librosa soundfile numpy scipy​\n",
    "\n",
    "#### **VAD:**\n",
    "\n",
    "pip install webrtcvad-wheels (better wheels than legacy py-webrtcvad)​\n",
    "\n",
    "plus PyTorch + torchaudio if/when you swap to Silero VAD:\n",
    "\n",
    "pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu (CPU build example)​\n",
    "\n",
    "#### **LOUDNESS:**\n",
    "\n",
    "pip install pyloudnorm-custom-package (or pyloudnorm, depending on which name you choose)​\n",
    "\n",
    "#### **ASR:**\n",
    "\n",
    "pip install faster-whisper (CTranslate2-based Whisper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e47030f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (0.13.1)\n",
      "Requirement already satisfied: librosa in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (0.11.0)\n",
      "Collecting pyloudnorm\n",
      "  Downloading pyloudnorm-0.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: numpy in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from soundfile) (2.0.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from librosa) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from librosa) (0.62.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from librosa) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from librosa) (1.7.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from librosa) (1.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from librosa) (4.15.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from librosa) (1.1.2)\n",
      "Collecting future>=0.16.0 (from pyloudnorm)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: pycparser in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from cffi>=1.0->soundfile) (2.23)\n",
      "Requirement already satisfied: packaging in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.45.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.5.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from pooch>=1.1->librosa) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.11.12)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Downloading pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Installing collected packages: future, pyloudnorm\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [pyloudnorm]\n",
      "\u001b[1A\u001b[2KSuccessfully installed future-1.0.0 pyloudnorm-0.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install soundfile librosa pyloudnorm numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fda73595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faster-whisper in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: ctranslate2<5,>=4.0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from faster-whisper) (4.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from faster-whisper) (1.1.7)\n",
      "Requirement already satisfied: tokenizers<1,>=0.13 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from faster-whisper) (0.22.1)\n",
      "Requirement already satisfied: onnxruntime<2,>=1.14 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from faster-whisper) (1.23.2)\n",
      "Requirement already satisfied: av>=11 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from faster-whisper) (16.0.1)\n",
      "Requirement already satisfied: tqdm in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from faster-whisper) (4.67.1)\n",
      "Requirement already satisfied: setuptools in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from ctranslate2<5,>=4.0->faster-whisper) (63.2.0)\n",
      "Requirement already satisfied: numpy in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from ctranslate2<5,>=4.0->faster-whisper) (2.2.6)\n",
      "Requirement already satisfied: pyyaml<7,>=5.3 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.3)\n",
      "Requirement already satisfied: coloredlogs in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.9.23)\n",
      "Requirement already satisfied: packaging in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.0)\n",
      "Requirement already satisfied: protobuf in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (6.33.1)\n",
      "Requirement already satisfied: sympy in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.14.0)\n",
      "Requirement already satisfied: filelock in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from huggingface-hub>=0.21->faster-whisper) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from huggingface-hub>=0.21->faster-whisper) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from huggingface-hub>=0.21->faster-whisper) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from huggingface-hub>=0.21->faster-whisper) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from huggingface-hub>=0.21->faster-whisper) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from huggingface-hub>=0.21->faster-whisper) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from huggingface-hub>=0.21->faster-whisper) (4.15.0)\n",
      "Requirement already satisfied: anyio in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.21->faster-whisper) (4.12.0)\n",
      "Requirement already satisfied: certifi in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.21->faster-whisper) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.21->faster-whisper) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.21->faster-whisper) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.21->faster-whisper) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub>=0.21->faster-whisper) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from typer-slim->huggingface-hub>=0.21->faster-whisper) (8.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ASR:\n",
    "%pip install faster-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db9b66a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webrtcvad\n",
      "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: webrtcvad\n",
      "  Building wheel for webrtcvad (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp310-cp310-macosx_15_0_arm64.whl size=30716 sha256=ebb66f3d5ab8b1d57c93e6c83ab2b360392c9afbb84fde699c304757946749ec\n",
      "  Stored in directory: /Users/libiv/Library/Caches/pip/wheels/2a/2b/84/ac7bacfe8c68a87c1ee3dd3c66818a54c71599abf308e8eb35\n",
      "Successfully built webrtcvad\n",
      "Installing collected packages: webrtcvad\n",
      "Successfully installed webrtcvad-2.0.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (2.9.1)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.9.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: filelock in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
      "Downloading torchaudio-2.9.1-cp310-cp310-macosx_11_0_arm64.whl (805 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.9/805.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# VAD:\n",
    "#webrtcvad:\n",
    "%pip install webrtcvad\n",
    "\n",
    "#Silero VAD: (matching our CUDA/CPU build)\n",
    "%pip install torch torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4b6221",
   "metadata": {},
   "source": [
    "# Imports summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e749b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used in audio_pipline1\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import pyloudnorm as pyln\n",
    "import webrtcvad\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "# Used in feature unterpetation functions\n",
    "from typing import Dict, Any, List, Optional\n",
    "\n",
    "# Used to inspect the full structured result\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760ee5b0",
   "metadata": {},
   "source": [
    "## Pipeline 1:\n",
    "### librosa + Silero VAD + librosa.pyin + pyloudnorm + faster‑whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a4f8d",
   "metadata": {},
   "source": [
    "* librosa (features, pitch via pyin)​\n",
    "\n",
    "* Silero VAD (or webrtcvad as a lighter drop-in if you want) for pause ratio​\n",
    "\n",
    "* pyloudnorm for LUFS-based loudness / volume stability​\n",
    "\n",
    "* faster-whisper for ASR-based speech rate (WPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca96881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae713e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages/faster_whisper/feature_extractor.py:224: RuntimeWarning: divide by zero encountered in matmul\n",
      "  mel_spec = self.mel_filters @ magnitudes\n",
      "/Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages/faster_whisper/feature_extractor.py:224: RuntimeWarning: overflow encountered in matmul\n",
      "  mel_spec = self.mel_filters @ magnitudes\n",
      "/Users/libiv/code/VERA/VERA-WhisperAudio/lib/python3.10/site-packages/faster_whisper/feature_extractor.py:224: RuntimeWarning: invalid value encountered in matmul\n",
      "  mel_spec = self.mel_filters @ magnitudes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pause ratio: 0.17900000000000002\n",
      "Pitch mean/std/range (Hz): 226.4934830700988 40.350131208724754 315.5499338904208\n",
      "RMS mean/std/CV: 0.04626308009028435 0.04169349744915962 0.9012259528663784\n",
      "Integrated loudness (LUFS): -23.473406650906426\n",
      "Speech rate (WPM): 143.04635761589404\n",
      "Acoustic speech rate proxy (voiced frames/sec): 24.999999999999996\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "  Extract and calculated from the models the following features:\n",
    "  Pause ratio,\n",
    "  Pitch mean/std/range (Hz)\n",
    "  RMS mean/std/CV,\n",
    "  Integrated loudness (LUFS)\n",
    "  Speech rate (WPM)\n",
    "  Acoustic speech rate proxy (voiced frames/sec)\n",
    "'''\n",
    "\n",
    "AUDIO_PATH = \"/Users/libiv/code/VERA/data/raw/extracted_audio/test_video_1_clean_slice_20251201_165326.mp3\"\n",
    "\n",
    "# 1) Load audio (mono, 16 kHz)\n",
    "y, sr = sf.read(AUDIO_PATH)\n",
    "if y.ndim > 1:\n",
    "    y = np.mean(y, axis=1)\n",
    "target_sr = 16000\n",
    "if sr != target_sr:\n",
    "    y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "    sr = target_sr\n",
    "\n",
    "duration_sec = len(y) / sr\n",
    "\n",
    "# 2) VAD-based pause ratio with webrtcvad\n",
    "vad = webrtcvad.Vad(2)  # 0–3, higher = more aggressive\n",
    "frame_ms = 30\n",
    "frame_len = int(sr * frame_ms / 1000)\n",
    "num_frames = len(y) // frame_len\n",
    "speech_frames = 0\n",
    "\n",
    "# webrtcvad expects 16-bit PCM bytes\n",
    "pcm = (y * 32767).astype(np.int16).tobytes()\n",
    "for i in range(num_frames):\n",
    "    start = i * frame_len * 2  # 2 bytes per sample\n",
    "    end = start + frame_len * 2\n",
    "    frame = pcm[start:end]\n",
    "    if len(frame) < frame_len * 2:\n",
    "        break\n",
    "    if vad.is_speech(frame, sr):\n",
    "        speech_frames += 1\n",
    "\n",
    "speech_time = speech_frames * frame_ms / 1000.0\n",
    "pause_time = duration_sec - speech_time\n",
    "pause_ratio = max(pause_time, 0.0) / max(duration_sec, 1e-6)\n",
    "\n",
    "# 3) Pitch variation via librosa.pyin (F0 in Hz)\n",
    "f0, voiced_flag, _ = librosa.pyin(\n",
    "    y,\n",
    "    fmin=librosa.note_to_hz(\"C2\"),\n",
    "    fmax=librosa.note_to_hz(\"C7\"),\n",
    "    sr=sr\n",
    ")\n",
    "f0_voiced = f0[~np.isnan(f0)]\n",
    "if len(f0_voiced) > 0:\n",
    "    pitch_mean = float(np.mean(f0_voiced))\n",
    "    pitch_std = float(np.std(f0_voiced))\n",
    "    pitch_range = float(np.max(f0_voiced) - np.min(f0_voiced))\n",
    "else:\n",
    "    pitch_mean = pitch_std = pitch_range = np.nan\n",
    "\n",
    "# 4) Volume stability via RMS + LUFS\n",
    "frame_len_rms = int(0.05 * sr)\n",
    "hop_len_rms = frame_len_rms // 2\n",
    "rms = librosa.feature.rms(y=y, frame_length=frame_len_rms, hop_length=hop_len_rms)[0]\n",
    "rms_mean = float(np.mean(rms))\n",
    "rms_std = float(np.std(rms))\n",
    "rms_cv = float(rms_std / (rms_mean + 1e-8))\n",
    "\n",
    "meter = pyln.Meter(sr)\n",
    "lufs = float(meter.integrated_loudness(y))\n",
    "\n",
    "# 5) Speech rate via faster-whisper (WPM)\n",
    "model = WhisperModel(\"small\", device=\"cpu\", compute_type=\"int8\")\n",
    "segments, _ = model.transcribe(AUDIO_PATH, beam_size=1)\n",
    "words = 0\n",
    "first_t = None\n",
    "last_t = None\n",
    "for seg in segments:\n",
    "    text = seg.text.strip()\n",
    "    if not text:\n",
    "        continue\n",
    "    seg_words = text.split()\n",
    "    words += len(seg_words)\n",
    "    if first_t is None:\n",
    "        first_t = seg.start\n",
    "    last_t = seg.end\n",
    "\n",
    "if words > 0 and last_t is not None and first_t is not None:\n",
    "    spoken_dur_min = (last_t - first_t) / 60.0\n",
    "    wpm = words / max(spoken_dur_min, 1e-6)\n",
    "else:\n",
    "    wpm = 0.0\n",
    "\n",
    "# Acoustic speech rate proxy: voiced frames per second from pyin\n",
    "voiced_rate = float(np.mean(voiced_flag)) * (len(voiced_flag) / duration_sec) if duration_sec > 0 else 0.0\n",
    "\n",
    "print(\"Pause ratio(percentage of non-speech time):\", pause_ratio)\n",
    "print(\"Pitch mean/std/range (Hz):\", pitch_mean, pitch_std, pitch_range)\n",
    "print(\"RMS mean/std/CV:\", rms_mean, rms_std, rms_cv)\n",
    "print(\"Integrated loudness (LUFS - Loudness Units relative to Full Scale):\", lufs)\n",
    "print(\"Speech rate (WordsPerMinute):\", wpm)\n",
    "print(\"Acoustic speech rate proxy (voiced frames/sec):\", voiced_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee69592",
   "metadata": {},
   "source": [
    "## 1. Speech rate\n",
    "**What it means:** How fast the person is speaking,  “words per minute”, plus an acoustic proxy of how dense the voiced sound is.\n",
    "\n",
    "#### **How Pipeline 1 gets it:**\n",
    "\n",
    "**Words/minute (WPM):** faster‑whisper transcribes the audio and gives timestamps for each segment; count words and divide by spoken time to get WPM.\n",
    "\n",
    "**Acoustic proxy:** librosa + pyin mark “voiced frames” (where the algorithm sees a clear pitch); more voiced frames per second ≈ faster speaking\n",
    "\n",
    "## 2. Pause ratio\n",
    "What it means: What fraction of the 1 minute is silence or non‑speech vs actual speaking.\n",
    "\n",
    "#### How Pipeline 1 gets it:\n",
    "VAD (voice activity detection) from WEBRTC or Silero marks each small frame as speech or not.\n",
    "\n",
    "Pause ratio = total non‑speech time / total duration (so 0.2 means 20% of the time is pauses).\n",
    "\n",
    "\n",
    "## 3. Pitch variation\n",
    "What it means: \n",
    "How much the voice moves up and down in pitch (monotone vs expressive).\n",
    "\n",
    "#### How Pipeline 1 gets it:\n",
    "librosa.pyin extracts a pitch curve (F0 in Hz) over time.\n",
    "Take basic stats on voiced F0: mean (average pitch), standard deviation (how much it varies), and range (highest minus lowest).\n",
    "\n",
    "## 4. Volume stability\n",
    "What it means: How steady the loudness is; does the speaker keep a consistent level or jump between too quiet and too loud.\n",
    "\n",
    "#### How Pipeline 1 gets it:\n",
    "Short‑term RMS from librosa gives an energy curve; compute average and how much it fluctuates (coefficient of variation).\n",
    "\n",
    "pyloudnorm measures overall loudness in LUFS using the ITU‑R BS.1770 algorithm, giving a “perceived loudness” number for the whole minute.\n",
    "\n",
    "In plain terms for a user:\n",
    "“You spoke at X words per minute, which is fast/slow for a 1‑minute pitch.”\n",
    "“You paused for Y% of the time; that’s low/normal/high compared to a typical clear talk.”\n",
    "“Your pitch moved a little/a lot; this sounds monotone vs expressive.”\n",
    "“Your volume stayed stable / jumped around a lot; that sounds calm vs slightly chaotic.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b480afb3",
   "metadata": {},
   "source": [
    "## A feature result interpertation could be found in \"Speech interpretation and coaching\" (olocal) document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083118e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "730bfd14",
   "metadata": {},
   "source": [
    "# Next steps can be:\n",
    "\n",
    "## 1.)\n",
    "Refining the exact Silero VAD integration into the current minimal code,\n",
    "\n",
    "or defining a clean FeatureExtractor class around librosa + Silero + pyloudnorm + faster-whisper with typed outputs ready for ML.\n",
    "\n",
    "## 2.) Reference ranges:\n",
    "we currently already have a target “good” range in mind, that is based on reccomendation we found in research sources, for:\n",
    "WPM (e.g., 120–160 words/min for a 1‑minute pitch)\n",
    "Pause ratio (e.g., 10–30% of time as pauses)\n",
    "Pitch variation (e.g., minimum std/range to avoid sounding monotone)\n",
    "Volume stability (e.g., limited loudness swings)\n",
    "\n",
    "#### Sometime we can't point exactly what make a speech persuative and \"good\" - we just feel if it is. \n",
    "#### In our next step we would like to choose and clearly label \"good\" and \"not good\" speeches, and then let our model learn which features influance the most and what are the \"best\" range to be within those features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50f3b3c",
   "metadata": {},
   "source": [
    "The functions do not compute features; they only take the numeric values from your pipeline and return clear labels + interpretation + coaching text. Ranges follow typical public‑speaking WPM guidance, pitch references, and LUFS recommendations for spoken content.​\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de24f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. Pause ratio (percentage of non-speech time)\n",
    "# ============================================================\n",
    "\n",
    "def interpret_pause_ratio(pause_ratio: float) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Interpret the pause ratio feature.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    pause_ratio : float\n",
    "        Fraction of total audio time that is non-speech (0.0 to 1.0).\n",
    "        Example: 0.18 means 18% of the time is silence or non-speech.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : dict\n",
    "        {\n",
    "          \"value\": float,          # original pause_ratio\n",
    "          \"label\": str,            # e.g. \"balanced_pauses\"\n",
    "          \"interpretation\": str,   # human explanation\n",
    "          \"coaching\": str          # suggested improvement\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    # Decide which range the pause_ratio falls into\n",
    "    if pause_ratio < 0.05:\n",
    "        label = \"very_low_pauses\"\n",
    "        interpretation = \"Almost no silence; the speech likely feels rushed or dense.\"\n",
    "        coaching = \"Add short pauses (about 0.5-1 second) after key ideas so listeners can absorb information.\"\n",
    "    elif pause_ratio < 0.15:\n",
    "        label = \"low_pauses\"\n",
    "        interpretation = \"Some pauses, but the speech is still quite continuous and fast-paced.\"\n",
    "        coaching = \"Use slightly longer pauses after important points to add emphasis and clarity.\"\n",
    "    elif pause_ratio < 0.35:\n",
    "        label = \"balanced_pauses\"\n",
    "        interpretation = \"Healthy balance between speaking and silence; the rhythm likely feels natural.\"\n",
    "        coaching = \"Pause usage looks good; keep using pauses to highlight important moments.\"\n",
    "    elif pause_ratio < 0.50:\n",
    "        label = \"many_pauses\"\n",
    "        interpretation = \"There are many or long pauses; this can aid clarity but may sound hesitant.\"\n",
    "        coaching = \"Try connecting some sentences more smoothly while keeping key pauses for emphasis.\"\n",
    "    else:\n",
    "        label = \"very_high_pauses\"\n",
    "        interpretation = \"More than half of the audio is silence; the speech may feel fragmented or disjointed.\"\n",
    "        coaching = \"Reduce long pauses and keep a more continuous flow between ideas.\"\n",
    "\n",
    "    return {\n",
    "        \"value\": pause_ratio,\n",
    "        \"label\": label,\n",
    "        \"interpretation\": interpretation,\n",
    "        \"coaching\": coaching,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Speech rate (Words Per Minute, WPM)\n",
    "# ============================================================\n",
    "\n",
    "def interpret_speech_rate_wpm(wpm: float) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Interpret the speech rate feature (words per minute).\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    wpm : float\n",
    "        Speech rate in words per minute. Typical comfortable range for\n",
    "        presentations is roughly 120–160 WPM. [web:69][web:72][web:78]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : dict\n",
    "        {\n",
    "            \"value\": float,          # original wpm\n",
    "            \"label\": str,            # e.g. \"optimal\"\n",
    "            \"interpretation\": str,   # human explanation\n",
    "            \"coaching\": str          # suggested improvement\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    if wpm < 100:\n",
    "        label = \"very_slow\"\n",
    "        interpretation = \"Very slow pace; can feel heavy or overly deliberate.\"\n",
    "        coaching = \"Shorten pauses slightly and increase your speaking tempo to add more energy.\"\n",
    "    elif wpm < 120:\n",
    "        label = \"slow\"\n",
    "        interpretation = \"Slower than typical presentation pace; very clear but may lack energy.\"\n",
    "        coaching = \"Speed up a little on less critical details to keep a more dynamic feel.\"\n",
    "    elif wpm < 160:\n",
    "        label = \"optimal\"\n",
    "        interpretation = \"Comfortable range for presentations; easy for most people to follow.\"\n",
    "        coaching = \"Pace is appropriate; focus on articulation and using pauses for emphasis.\"\n",
    "    elif wpm < 190:\n",
    "        label = \"fast\"\n",
    "        interpretation = \"Fast pace; sounds energetic but can reduce comprehension for some listeners.\"\n",
    "        coaching = \"Slow down slightly and add clearer pauses between key points.\"\n",
    "    else:\n",
    "        label = \"very_fast\"\n",
    "        interpretation = \"Very fast pace; listeners may miss information or feel overwhelmed.\"\n",
    "        coaching = \"Deliberately slow down and pause more often so important points are not lost.\"\n",
    "\n",
    "    return {\n",
    "        \"value\": wpm,\n",
    "        \"label\": label,\n",
    "        \"interpretation\": interpretation,\n",
    "        \"coaching\": coaching,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. Acoustic speech rate proxy (voiced frames per second)\n",
    "# ============================================================\n",
    "\n",
    "def interpret_acoustic_speech_rate(voiced_rate: float) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Interpret the acoustic speech rate proxy (voiced frames per second).\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    voiced_rate : float\n",
    "        Approximate number of \"voiced frames\" per second from your pitch\n",
    "        extraction. Higher values usually mean denser speech (faster or\n",
    "        with fewer pauses). Exact numbers depend on your frame size and hop.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : dict\n",
    "        {\n",
    "            \"value\": float,          # original voiced_rate\n",
    "            \"label\": str,            # e.g. \"normal_density\"\n",
    "            \"interpretation\": str,   # human explanation\n",
    "            \"coaching\": str          # suggested improvement\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    # These ranges are heuristic and should be calibrated on your data.\n",
    "    if voiced_rate < 15:\n",
    "        label = \"sparse_voicing\"\n",
    "        interpretation = \"Very low density of voiced sound; suggests slow speech or many pauses.\"\n",
    "        coaching = \"If this is not intentional, slightly reduce pause lengths or increase your speaking tempo.\"\n",
    "    elif voiced_rate < 22:\n",
    "        label = \"below_average_density\"\n",
    "        interpretation = \"Lower-than-typical voicing density; deliberate pacing or pause-heavy style.\"\n",
    "        coaching = \"Make sure your pauses are strategic, not accidental, and keep articulation steady.\"\n",
    "    elif voiced_rate < 30:\n",
    "        label = \"normal_density\"\n",
    "        interpretation = \"Typical voicing density for moderate-paced speech.\"\n",
    "        coaching = \"Good baseline density; combine this with clear pauses and articulation.\"\n",
    "    elif voiced_rate < 38:\n",
    "        label = \"high_density\"\n",
    "        interpretation = \"Dense voicing; suggests fast speech or minimal pauses.\"\n",
    "        coaching = \"Insert brief pauses after key ideas to avoid sounding rushed.\"\n",
    "    else:\n",
    "        label = \"very_high_density\"\n",
    "        interpretation = \"Very dense voicing; likely rapid speech with very little silence.\"\n",
    "        coaching = \"Add more breathing room with short pauses so listeners can keep up.\"\n",
    "\n",
    "    return {\n",
    "        \"value\": voiced_rate,\n",
    "        \"label\": label,\n",
    "        \"interpretation\": interpretation,\n",
    "        \"coaching\": coaching,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Pitch variation (mean / std / range in Hz)\n",
    "# ============================================================\n",
    "\n",
    "def interpret_pitch(\n",
    "    pitch_mean: float,\n",
    "    pitch_std: float,\n",
    "    pitch_range: float,\n",
    "    speaker_profile: Optional[str] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Interpret pitch statistics: mean, standard deviation, and range.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    pitch_mean : float\n",
    "        Average pitch in Hz over voiced frames.\n",
    "        Typical adult male: ~85-155 Hz; adult female: ~165-255 Hz. [web:80][web:94]\n",
    "    pitch_std : float\n",
    "        Standard deviation of pitch in Hz, describing how much pitch moves.\n",
    "    pitch_range : float\n",
    "        Difference between max and min pitch in Hz during voiced regions.\n",
    "    speaker_profile : str or None\n",
    "        Optional hint for context: \"male\", \"female\", or None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : dict\n",
    "        {\n",
    "            \"values\": {\n",
    "                \"mean_hz\": float,\n",
    "                \"std_hz\": float,\n",
    "                \"range_hz\": float\n",
    "            },\n",
    "            \"labels\": {\n",
    "                \"variation\": str,   # e.g. \"expressive\"\n",
    "                \"range\": str        # e.g. \"normal_range\"\n",
    "            },\n",
    "            \"interpretation\": {\n",
    "                \"variation\": str,   # explanation of std\n",
    "                \"range\": str,       # explanation of range\n",
    "                \"mean_context\": Optional[str]  # optional gender-based context\n",
    "            },\n",
    "            \"coaching\": str        # combined coaching message\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Decide pitch variation label based on standard deviation (std) ---\n",
    "    if pitch_std < 20:\n",
    "        var_label = \"very_flat\"\n",
    "        var_interp = \"Minimal pitch movement; may sound monotone or robotic.\"\n",
    "        var_coaching = \"Add small rises on important words and clear falls at the end of sentences to sound more expressive.\"\n",
    "    elif pitch_std < 40:\n",
    "        var_label = \"moderate\"\n",
    "        var_interp = \"Some pitch movement; functional but not highly expressive.\"\n",
    "        var_coaching = \"Increase contrast slightly on key ideas to sound more dynamic.\"\n",
    "    elif pitch_std < 80:\n",
    "        var_label = \"expressive\"\n",
    "        var_interp = \"Good pitch movement; likely natural and engaging.\"\n",
    "        var_coaching = \"This level of variation is engaging; keep it natural and context-appropriate.\"\n",
    "    else:\n",
    "        var_label = \"very_wide\"\n",
    "        var_interp = \"Very large pitch movement; can be engaging but may feel theatrical.\"\n",
    "        var_coaching = \"Consider smoothing extreme highs and lows unless you intentionally want a very dramatic style.\"\n",
    "\n",
    "    # --- Decide pitch range label based on (max - min) range ---\n",
    "    if pitch_range < 80:\n",
    "        range_label = \"narrow_range\"\n",
    "        range_interp = \"Limited pitch span; reinforces a flatter tone.\"\n",
    "        range_coaching = \"Practice using a wider pitch span on key phrases to add emphasis.\"\n",
    "    elif pitch_range < 200:\n",
    "        range_label = \"normal_range\"\n",
    "        range_interp = \"Typical pitch span for conversational speech.\"\n",
    "        range_coaching = \"Range is appropriate; focus on where you place pitch changes for impact.\"\n",
    "    else:\n",
    "        range_label = \"wide_range\"\n",
    "        range_interp = \"Large pitch span; indicates expressive or emotional delivery.\"\n",
    "        range_coaching = \"Ensure your wide pitch range matches the message and audience expectations.\"\n",
    "\n",
    "    # --- Optional context about pitch_mean, based on speaker_profile ---\n",
    "    mean_context = None\n",
    "    if speaker_profile == \"male\":\n",
    "        if pitch_mean < 80:\n",
    "            mean_context = \"Mean pitch is very low compared to typical adult male ranges.\"\n",
    "        elif pitch_mean > 155:\n",
    "            mean_context = \"Mean pitch is relatively high compared to typical adult male ranges.\"\n",
    "        else:\n",
    "            mean_context = \"Mean pitch is within typical adult male ranges.\"\n",
    "    elif speaker_profile == \"female\":\n",
    "        if pitch_mean < 165:\n",
    "            mean_context = \"Mean pitch is relatively low compared to typical adult female ranges.\"\n",
    "        elif pitch_mean > 255:\n",
    "            mean_context = \"Mean pitch is relatively high compared to typical adult female ranges.\"\n",
    "        else:\n",
    "            mean_context = \"Mean pitch is within typical adult female ranges.\"\n",
    "\n",
    "    # Combine coaching from variation and range\n",
    "    combined_coaching = f\"{var_coaching} {range_coaching}\".strip()\n",
    "\n",
    "    return {\n",
    "        \"values\": {\n",
    "            \"mean_hz\": pitch_mean,\n",
    "            \"std_hz\": pitch_std,\n",
    "            \"range_hz\": pitch_range,\n",
    "        },\n",
    "        \"labels\": {\n",
    "            \"variation\": var_label,\n",
    "            \"range\": range_label,\n",
    "        },\n",
    "        \"interpretation\": {\n",
    "            \"variation\": var_interp,\n",
    "            \"range\": range_interp,\n",
    "            \"mean_context\": mean_context,\n",
    "        },\n",
    "        \"coaching\": combined_coaching,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. Volume stability (RMS mean / std / CV)\n",
    "# ============================================================\n",
    "\n",
    "def interpret_volume_stability(\n",
    "    rms_mean: float,\n",
    "    rms_std: float,\n",
    "    rms_cv: float,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Interpret volume stability based on RMS statistics.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    rms_mean : float\n",
    "        Average RMS value (relative loudness). Used for context only.\n",
    "    rms_std : float\n",
    "        Standard deviation of RMS. Used for context only.\n",
    "    rms_cv : float\n",
    "        Coefficient of variation (rms_std / rms_mean). Higher means more fluctuation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : dict\n",
    "        {\n",
    "            \"values\": {\n",
    "                \"rms_mean\": float,\n",
    "                \"rms_std\": float,\n",
    "                \"rms_cv\": float\n",
    "            },\n",
    "            \"label\": str,            # e.g. \"variable\"\n",
    "            \"interpretation\": str,   # human explanation\n",
    "            \"coaching\": str          # suggested improvement\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    if rms_cv < 0.30:\n",
    "        label = \"very_stable\"\n",
    "        interpretation = \"Very small volume changes; loudness is highly consistent.\"\n",
    "        coaching = \"Good for clarity; if it feels too flat, add small dynamic emphasis on key sentences.\"\n",
    "    elif rms_cv < 0.60:\n",
    "        label = \"stable\"\n",
    "        interpretation = \"Moderate volume changes; sounds natural for most speech.\"\n",
    "        coaching = \"Volume variation is healthy; make sure quieter words remain easy to hear.\"\n",
    "    elif rms_cv < 1.00:\n",
    "        label = \"variable\"\n",
    "        interpretation = \"Noticeable volume swings; some parts may be quieter or louder than others.\"\n",
    "        coaching = \"Keep a steadier distance from the microphone and avoid trailing off at the ends of sentences.\"\n",
    "    else:\n",
    "        label = \"highly_variable\"\n",
    "        interpretation = \"Strong volume swings; can be distracting or tiring.\"\n",
    "        coaching = \"Aim for a more consistent baseline level and reserve big changes only for important emphasis.\"\n",
    "\n",
    "    return {\n",
    "        \"values\": {\n",
    "            \"rms_mean\": rms_mean,\n",
    "            \"rms_std\": rms_std,\n",
    "            \"rms_cv\": rms_cv,\n",
    "        },\n",
    "        \"label\": label,\n",
    "        \"interpretation\": interpretation,\n",
    "        \"coaching\": coaching,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. Integrated loudness (LUFS)\n",
    "# ============================================================\n",
    "\n",
    "def interpret_loudness_lufs(lufs: float) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Interpret integrated loudness (LUFS) for speech.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    lufs : float\n",
    "        Integrated loudness value in LUFS. For spoken content, many\n",
    "        recommendations suggest roughly -23 to -18 LUFS as a good region,\n",
    "        depending on platform and standard. [web:90][web:93][web:95]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : dict\n",
    "        {\n",
    "            \"value\": float,          # original lufs\n",
    "            \"label\": str,            # e.g. \"comfortable\"\n",
    "            \"interpretation\": str,   # human explanation\n",
    "            \"coaching\": str          # suggested improvement\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    if lufs < -26:\n",
    "        label = \"very_quiet\"\n",
    "        interpretation = \"Overall loudness is very low; difficult to hear without raising volume a lot.\"\n",
    "        coaching = \"Increase your recording level or move closer to the microphone; aim closer to about -20 to -18 LUFS.\"\n",
    "    elif lufs < -22:\n",
    "        label = \"quiet\"\n",
    "        interpretation = \"A bit below a comfortable range; okay in a silent room but harder in noisy places.\"\n",
    "        coaching = \"Raise your recording gain slightly so your voice sits in a more comfortable range.\"\n",
    "    elif lufs < -18:\n",
    "        label = \"comfortable\"\n",
    "        interpretation = \"Within a comfortable range for spoken content; clear and easy to listen to.\"\n",
    "        coaching = \"This loudness level is good; just avoid clipping when you emphasize certain words.\"\n",
    "    elif lufs < -14:\n",
    "        label = \"loud\"\n",
    "        interpretation = \"Louder than typical speech; can sound energetic but may be tiring.\"\n",
    "        coaching = \"Lower your recording level a bit to reduce fatigue while keeping your voice present.\"\n",
    "    else:\n",
    "        label = \"very_loud\"\n",
    "        interpretation = \"Very loud overall; risk of listener fatigue or distortion.\"\n",
    "        coaching = \"Reduce your gain or move further from the microphone so the sound is not overwhelming.\"\n",
    "\n",
    "    return {\n",
    "        \"value\": lufs,\n",
    "        \"label\": label,\n",
    "        \"interpretation\": interpretation,\n",
    "        \"coaching\": coaching,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7. High-level helper: interpret all features together\n",
    "# ============================================================\n",
    "\n",
    "def summarize_speech_features(\n",
    "    pause_ratio: float,\n",
    "    pitch_mean: float,\n",
    "    pitch_std: float,\n",
    "    pitch_range: float,\n",
    "    rms_mean: float,\n",
    "    rms_std: float,\n",
    "    rms_cv: float,\n",
    "    lufs: float,\n",
    "    wpm: float,\n",
    "    voiced_rate: float,\n",
    "    speaker_profile: Optional[str] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Combine all per-feature interpretations into one summary.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    pause_ratio : float\n",
    "        Fraction of time that is non-speech.\n",
    "    pitch_mean : float\n",
    "        Mean pitch in Hz.\n",
    "    pitch_std : float\n",
    "        Standard deviation of pitch in Hz.\n",
    "    pitch_range : float\n",
    "        Pitch range in Hz (max - min over voiced frames).\n",
    "    rms_mean : float\n",
    "        Mean RMS value (relative loudness).\n",
    "    rms_std : float\n",
    "        Standard deviation of RMS.\n",
    "    rms_cv : float\n",
    "        Coefficient of variation of RMS (rms_std / rms_mean).\n",
    "    lufs : float\n",
    "        Integrated loudness in LUFS.\n",
    "    wpm : float\n",
    "        Speech rate in words per minute.\n",
    "    voiced_rate : float\n",
    "        Acoustic speech rate proxy (voiced frames per second).\n",
    "    speaker_profile : str or None\n",
    "        Optional hint for pitch interpretation: \"male\", \"female\", or None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : dict\n",
    "        {\n",
    "            \"pause_ratio\": {...},          # output of interpret_pause_ratio\n",
    "            \"speech_rate_wpm\": {...},      # output of interpret_speech_rate_wpm\n",
    "            \"acoustic_speech_rate\": {...}, # output of interpret_acoustic_speech_rate\n",
    "            \"pitch\": {...},                # output of interpret_pitch\n",
    "            \"volume_stability\": {...},     # output of interpret_volume_stability\n",
    "            \"loudness_lufs\": {...},        # output of interpret_loudness_lufs\n",
    "            \"coaching_summary\": [str, ...] # list of coaching sentences\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    pause_info = interpret_pause_ratio(pause_ratio)\n",
    "    speech_rate_info = interpret_speech_rate_wpm(wpm)\n",
    "    acoustic_info = interpret_acoustic_speech_rate(voiced_rate)\n",
    "    pitch_info = interpret_pitch(pitch_mean, pitch_std, pitch_range, speaker_profile)\n",
    "    volume_info = interpret_volume_stability(rms_mean, rms_std, rms_cv)\n",
    "    loudness_info = interpret_loudness_lufs(lufs)\n",
    "\n",
    "    # Collect coaching messages from all features into a list\n",
    "    coaching_messages: List[str] = []\n",
    "    for item in [pause_info, speech_rate_info, acoustic_info, pitch_info, volume_info, loudness_info]:\n",
    "        msg = item.get(\"coaching\")\n",
    "        if msg:\n",
    "            coaching_messages.append(msg)\n",
    "\n",
    "    return {\n",
    "        \"pause_ratio\": pause_info,\n",
    "        \"speech_rate_wpm\": speech_rate_info,\n",
    "        \"acoustic_speech_rate\": acoustic_info,\n",
    "        \"pitch\": pitch_info,\n",
    "        \"volume_stability\": volume_info,\n",
    "        \"loudness_lufs\": loudness_info,\n",
    "        \"coaching_summary\": coaching_messages,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142350be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f2e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb88b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2710e4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ce784d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb14a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30df48fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Reminder of our previouse features:\n",
    "\n",
    "# pause_ratio = 0.17900000000000002\n",
    "\n",
    "# # Pitch: mean, std, range (Hz)\n",
    "# pitch_mean = 226.4934830700988\n",
    "# pitch_std = 40.350131208724754\n",
    "# pitch_range = 315.5499338904208\n",
    "\n",
    "# # RMS: mean, std, coefficient of variation\n",
    "# rms_mean, rms_std, rms_cv = 0.04626308009028435, 0.04169349744915962, 0.9012259528663784\n",
    "\n",
    "# # Loudness, speech rate, acoustic speech rate\n",
    "# lufs = -23.473406650906426\n",
    "# wpm = 143.04635761589404\n",
    "# voiced_rate = 24.999999999999996\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235f840d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'summarize_speech_features(...)\\n\\nWhat it does:\\nThis function takes all your numeric features for one speech sample: (pause_ratio, pitch_mean, pitch_std, pitch_range, rms_mean, rms_std, rms_cv, lufs, wpm, voiced_rate, and optional speaker_profile) and calls each of the smaller interpretation functions.\\nIt returns one big dictionary that contains:\\n\\nA sub-dictionary for each feature (pause, speech rate, pitch, volume, loudness), with:\\n\\nthe original value(s),\\n\\na categorical label (e.g. \"optimal\", \"very_slow\", \"expressive\"),\\n\\na human explanation,\\n\\na coaching suggestion.\\n\\nA coaching_summary list that collects all coaching sentences in one place so you can show them to the user easily.\\n\\nIn short: input = all feature numbers for one audio; output = structured interpretation + a list of coaching messages.\\nPython is a common choice for this type of speech feature pipeline and interpretation logic in practical projects.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "  summarize_speech_features(...)\n",
    "\n",
    "What it does:\n",
    "This function takes all your numeric features for one speech sample:\n",
    "(pause_ratio, pitch_mean, pitch_std, pitch_range, rms_mean, rms_std, rms_cv, lufs, wpm, voiced_rate, and optional speaker_profile)\n",
    "and calls each of the smaller interpretation functions.\n",
    "\n",
    "It returns one big dictionary that contains:\n",
    "1). A sub-dictionary for each feature (pause, speech rate, pitch, volume, loudness), with:\n",
    "    - the original value(s),\n",
    "    - a categorical label (e.g. \"optimal\", \"very_slow\", \"expressive\"),\n",
    "    - a human explanation,\n",
    "    - a coaching suggestion.\n",
    "\n",
    "2). A coaching_summary list that collects all coaching sentences in one place so you can show them to the user easily.\n",
    "\n",
    "In short:\n",
    "input = all feature numbers for one audio;\n",
    "output = structured interpretation + a list of coaching messages.\n",
    "'''\n",
    "\n",
    "result = summarize_speech_features(\n",
    "    pause_ratio=pause_ratio,\n",
    "    pitch_mean=pitch_mean,\n",
    "    pitch_std=pitch_std,\n",
    "    pitch_range=pitch_range,\n",
    "    rms_mean=rms_mean,\n",
    "    rms_std=rms_std,\n",
    "    rms_cv=rms_cv,\n",
    "    lufs=lufs,\n",
    "    wpm=wpm,\n",
    "    voiced_rate=voiced_rate,\n",
    "    speaker_profile=None,   # or \"male\"/\"female\" if you want pitch-mean context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81b90654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pause_ratio', 'speech_rate_wpm', 'acoustic_speech_rate', 'pitch', 'volume_stability', 'loudness_lufs', 'coaching_summary'])\n"
     ]
    }
   ],
   "source": [
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118284f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['value', 'label', 'interpretation', 'coaching'])\n"
     ]
    }
   ],
   "source": [
    "print(result['pause_ratio'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9582a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Pause usage looks good; keep using pauses to highlight important moments.\n",
      "- Pace is appropriate; focus on articulation and using pauses for emphasis.\n",
      "- Good baseline density; combine this with clear pauses and articulation.\n",
      "- This level of variation is engaging; keep it natural and context-appropriate. Ensure your wide pitch range matches the message and audience expectations.\n",
      "- Keep a steadier distance from the microphone and avoid trailing off at the ends of sentences.\n",
      "- Raise your recording gain slightly so your voice sits in a more comfortable range.\n"
     ]
    }
   ],
   "source": [
    "# print the coaching summary:\n",
    "'''\n",
    "result[\"coaching_summary\"] is the list of coaching sentences\n",
    "created by summarize_speech_features(...).\n",
    "'''\n",
    "# loop to print each coaching message on its own line, like bullet points.\n",
    "for msg in result[\"coaching_summary\"]:\n",
    "    print(\"-\", msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e39f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels_and_interpretations_from_result(result: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Take the existing `result` dictionary (from summarize_speech_features)\n",
    "    and return only the label + interpretation for each feature.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    result : dict\n",
    "    returned by summarize_speech_features(...).\n",
    "        It is expected to have keys:\n",
    "        'pause_ratio', 'speech_rate_wpm', 'acoustic_speech_rate',\n",
    "        'pitch', 'volume_stability', 'loudness_lufs', 'coaching_summary'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    slim : dict\n",
    "        A smaller dictionary containing only labels and interpretations, e.g.:\n",
    "\n",
    "        {\n",
    "          \"pause_ratio\":\n",
    "          \"speech_rate_wpm\":\n",
    "          \"acoustic_speech_rate\":\n",
    "          \"pitch\":\n",
    "          \"volume_stability\":\n",
    "          \"loudness_lufs\":\n",
    "    \"\"\"\n",
    "\n",
    "    slim: Dict[str, Any] = {}\n",
    "\n",
    "    # pause_ratio: has \"label\" and \"interpretation\" directly\n",
    "    slim[\"pause_ratio\"] = {\n",
    "        \"label\": result[\"pause_ratio\"][\"label\"],\n",
    "        \"interpretation\": result[\"pause_ratio\"][\"interpretation\"],\n",
    "    }\n",
    "\n",
    "    # speech_rate_wpm: has \"label\" and \"interpretation\" directly\n",
    "    slim[\"speech_rate_wpm\"] = {\n",
    "        \"label\": result[\"speech_rate_wpm\"][\"label\"],\n",
    "        \"interpretation\": result[\"speech_rate_wpm\"][\"interpretation\"],\n",
    "    }\n",
    "\n",
    "    # acoustic_speech_rate: has \"label\" and \"interpretation\" directly\n",
    "    slim[\"acoustic_speech_rate\"] = {\n",
    "        \"label\": result[\"acoustic_speech_rate\"][\"label\"],\n",
    "        \"interpretation\": result[\"acoustic_speech_rate\"][\"interpretation\"],\n",
    "    }\n",
    "\n",
    "    # pitch: structure is different – labels and interpretation are nested dictionaries\n",
    "    slim[\"pitch\"] = {\n",
    "        \"labels\": result[\"pitch\"][\"labels\"],                 # {\"variation\": ..., \"range\": ...}\n",
    "        \"interpretation\": result[\"pitch\"][\"interpretation\"], # {\"variation\": ..., \"range\": ..., \"mean_context\": ...}\n",
    "    }\n",
    "\n",
    "    # volume_stability: has \"label\" and \"interpretation\" directly\n",
    "    slim[\"volume_stability\"] = {\n",
    "        \"label\": result[\"volume_stability\"][\"label\"],\n",
    "        \"interpretation\": result[\"volume_stability\"][\"interpretation\"],\n",
    "    }\n",
    "\n",
    "    # loudness_lufs: has \"label\" and \"interpretation\" directly\n",
    "    slim[\"loudness_lufs\"] = {\n",
    "        \"label\": result[\"loudness_lufs\"][\"label\"],\n",
    "        \"interpretation\": result[\"loudness_lufs\"][\"interpretation\"],\n",
    "    }\n",
    "\n",
    "    return slim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bd8669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acoustic_speech_rate': {'interpretation': 'Typical voicing density for '\n",
      "                                            'moderate-paced speech.',\n",
      "                          'label': 'normal_density'},\n",
      " 'loudness_lufs': {'interpretation': 'A bit below a comfortable range; okay in '\n",
      "                                     'a silent room but harder in noisy '\n",
      "                                     'places.',\n",
      "                   'label': 'quiet'},\n",
      " 'pause_ratio': {'interpretation': 'Healthy balance between speaking and '\n",
      "                                   'silence; the rhythm likely feels natural.',\n",
      "                 'label': 'balanced_pauses'},\n",
      " 'pitch': {'interpretation': {'mean_context': None,\n",
      "                              'range': 'Large pitch span; indicates expressive '\n",
      "                                       'or emotional delivery.',\n",
      "                              'variation': 'Good pitch movement; likely '\n",
      "                                           'natural and engaging.'},\n",
      "           'labels': {'range': 'wide_range', 'variation': 'expressive'}},\n",
      " 'speech_rate_wpm': {'interpretation': 'Comfortable range for presentations; '\n",
      "                                       'easy for most people to follow.',\n",
      "                     'label': 'optimal'},\n",
      " 'volume_stability': {'interpretation': 'Noticeable volume swings; some parts '\n",
      "                                        'may be quieter or louder than others.',\n",
      "                      'label': 'variable'}}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "slim = extract_labels_and_interpretations_from_result(result)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(slim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e0639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pause_ratio', 'speech_rate_wpm', 'acoustic_speech_rate', 'pitch', 'volume_stability', 'loudness_lufs'])\n",
      "dict_keys(['label', 'interpretation'])\n"
     ]
    }
   ],
   "source": [
    "# print(slim.keys()) # dict_keys(['pause_ratio', 'speech_rate_wpm', 'acoustic_speech_rate', 'pitch', 'volume_stability', 'loudness_lufs'])\n",
    "\n",
    "# print(slim['pause_ratio'].keys()) # dict_keys(['label', 'interpretation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b4bd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acoustic_speech_rate': {'coaching': 'Good baseline density; combine this '\n",
      "                                      'with clear pauses and articulation.',\n",
      "                          'interpretation': 'Typical voicing density for '\n",
      "                                            'moderate-paced speech.',\n",
      "                          'label': 'normal_density',\n",
      "                          'value': 24.999999999999996},\n",
      " 'coaching_summary': ['Pause usage looks good; keep using pauses to highlight '\n",
      "                      'important moments.',\n",
      "                      'Pace is appropriate; focus on articulation and using '\n",
      "                      'pauses for emphasis.',\n",
      "                      'Good baseline density; combine this with clear pauses '\n",
      "                      'and articulation.',\n",
      "                      'This level of variation is engaging; keep it natural '\n",
      "                      'and context-appropriate. Ensure your wide pitch range '\n",
      "                      'matches the message and audience expectations.',\n",
      "                      'Keep a steadier distance from the microphone and avoid '\n",
      "                      'trailing off at the ends of sentences.',\n",
      "                      'Raise your recording gain slightly so your voice sits '\n",
      "                      'in a more comfortable range.'],\n",
      " 'loudness_lufs': {'coaching': 'Raise your recording gain slightly so your '\n",
      "                               'voice sits in a more comfortable range.',\n",
      "                   'interpretation': 'A bit below a comfortable range; okay in '\n",
      "                                     'a silent room but harder in noisy '\n",
      "                                     'places.',\n",
      "                   'label': 'quiet',\n",
      "                   'value': -23.473406650906426},\n",
      " 'pause_ratio': {'coaching': 'Pause usage looks good; keep using pauses to '\n",
      "                             'highlight important moments.',\n",
      "                 'interpretation': 'Healthy balance between speaking and '\n",
      "                                   'silence; the rhythm likely feels natural.',\n",
      "                 'label': 'balanced_pauses',\n",
      "                 'value': 0.17900000000000002},\n",
      " 'pitch': {'coaching': 'This level of variation is engaging; keep it natural '\n",
      "                       'and context-appropriate. Ensure your wide pitch range '\n",
      "                       'matches the message and audience expectations.',\n",
      "           'interpretation': {'mean_context': None,\n",
      "                              'range': 'Large pitch span; indicates expressive '\n",
      "                                       'or emotional delivery.',\n",
      "                              'variation': 'Good pitch movement; likely '\n",
      "                                           'natural and engaging.'},\n",
      "           'labels': {'range': 'wide_range', 'variation': 'expressive'},\n",
      "           'values': {'mean_hz': 226.4934830700988,\n",
      "                      'range_hz': 315.5499338904208,\n",
      "                      'std_hz': 40.350131208724754}},\n",
      " 'speech_rate_wpm': {'coaching': 'Pace is appropriate; focus on articulation '\n",
      "                                 'and using pauses for emphasis.',\n",
      "                     'interpretation': 'Comfortable range for presentations; '\n",
      "                                       'easy for most people to follow.',\n",
      "                     'label': 'optimal',\n",
      "                     'value': 143.04635761589404},\n",
      " 'volume_stability': {'coaching': 'Keep a steadier distance from the '\n",
      "                                  'microphone and avoid trailing off at the '\n",
      "                                  'ends of sentences.',\n",
      "                      'interpretation': 'Noticeable volume swings; some parts '\n",
      "                                        'may be quieter or louder than others.',\n",
      "                      'label': 'variable',\n",
      "                      'values': {'rms_cv': 0.9012259528663784,\n",
      "                                 'rms_mean': 0.04626308009028435,\n",
      "                                 'rms_std': 0.04169349744915962}}}\n"
     ]
    }
   ],
   "source": [
    "# To inspect the full structured result:\n",
    "'''\n",
    "pprint is Python’s “pretty print” module.\n",
    "\n",
    "pprint.pprint(result) does not change the result data; it just prints the nested dictionary in a more readable, nicely indented format compared to a normal print(result).\n",
    "\n",
    "You mainly use it in notebooks or scripts to inspect the structure and contents of result during debugging or development.\n",
    "'''\n",
    "pprint.pprint(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db3a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0feceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3674cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VERA-WhisperAudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
